# üìä DIFF VISUEL - Copilot API Enhancement

## Fichier: `app/api/admin/copilot/route.ts`

---

## üî¥ ANCIENNE VERSION (Brid√©e)

```typescript
import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

// ‚ùå Actions limit√©es (3 types seulement)
const buildActions = (message: string) => {
  const actions = [];
  const text = message.toLowerCase();

  if (text.includes('crawl')) { /* launch_crawl */ }
  if (text.includes('score')) { /* run_job */ }
  if (text.includes('health')) { /* health_check */ }

  return actions;
};

// ‚ùå R√©ponse basique
const buildFallbackResponse = (message: string, context?: Record<string, unknown>) => {
  return 'Pilote is online. I can help you monitor crawls, jobs, and validations.';
};

// ‚ùå POST limit√©
export async function POST(request: NextRequest) {
  const { message, context } = await request.json();

  // ‚ùå Prompt restrictif
  const systemPrompt = 'You are Pilote, an operations assistant for GTIXT. Be concise, actionable, and focus on admin operations.';

  const completion = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: `Context: ${JSON.stringify(context)}\n\nUser: ${message}` }
    ],
    temperature: 0.3,        // ‚ùå Peu cr√©atif
    max_tokens: 400,         // ‚ùå R√©ponses courtes
  });

  return NextResponse.json({
    success: true,
    response: completion.choices[0].message.content,
    actions: buildActions(message),
    // ‚ùå Pas d'info sur l'usage des tokens
  });
}
```

**Limitations**:
- ‚ùå Pas de lecture de fichiers
- ‚ùå Pas de g√©n√©ration de patches
- ‚ùå Pas de diffs
- ‚ùå R√©ponses courtes (400 tokens max)
- ‚ùå Pas de m√©moire conversationnelle
- ‚ùå Prompt tr√®s restrictif
- ‚ùå Temperature basse (0.3) = peu cr√©atif
- ‚ùå Pas de mode agent

---

## üü¢ NOUVELLE VERSION (D√©brid√©e)

```typescript
import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import fs from 'fs/promises';           // ‚úÖ Lecture filesystem
import path from 'path';                 // ‚úÖ Manipulation paths
import { exec } from 'child_process';    // ‚úÖ Commandes shell
import { promisify } from 'util';

const execAsync = promisify(exec);

// ‚úÖ 8 types d'actions (vs 3 avant)
const buildActions = (message: string) => {
  const actions = [];
  const text = message.toLowerCase();

  if (text.includes('crawl')) { /* launch_crawl */ }
  if (text.includes('score')) { /* run_job */ }
  if (text.includes('health')) { /* health_check */ }
  
  // ‚úÖ NOUVEAUX
  if (text.includes('read') || text.includes('file')) { 
    actions.push({ type: 'read_file', label: 'Read File' }); 
  }
  if (text.includes('patch') || text.includes('fix')) { 
    actions.push({ type: 'generate_patch', label: 'Generate Patch' }); 
  }
  if (text.includes('diff')) { 
    actions.push({ type: 'show_diff', label: 'Show Diff' }); 
  }
  if (text.includes('impact')) { 
    actions.push({ type: 'analyze_impact', label: 'Analyze Impact' }); 
  }
  if (text.includes('plan')) { 
    actions.push({ type: 'action_plan', label: 'Create Action Plan' }); 
  }

  return actions;
};

// ‚úÖ Nouvelles fonctions utilitaires
const readWorkspaceFile = async (filePath: string): Promise<string> => {
  const fullPath = path.join('/opt/gpti', filePath);
  const content = await fs.readFile(fullPath, 'utf-8');
  return content;
};

const generateDiff = async (file1: string, file2: string): Promise<string> => {
  const { stdout } = await execAsync(`diff -u "${file1}" "${file2}"`);
  return stdout;
};

const listWorkspaceFiles = async (directory: string = ''): Promise<string[]> => {
  const fullPath = path.join('/opt/gpti/gpti-site', directory);
  const files = await fs.readdir(fullPath);
  return files;
};

// ‚úÖ R√©ponse enrichie
const buildFallbackResponse = (message: string, context?: Record<string, unknown>) => {
  return `ü§ñ **Pilote AI GTiXT** - Assistant Op√©rationnel Avanc√©

Je peux vous aider avec:
‚Ä¢ üìñ Lire et analyser des fichiers
‚Ä¢ üîß Proposer des patches et corrections
‚Ä¢ üìä G√©n√©rer des diffs et comparaisons
‚Ä¢ üí° Expliquer les impacts de changements
‚Ä¢ üìã Cr√©er des plans d'action d√©taill√©s
‚Ä¢ üï∑Ô∏è G√©rer les crawls et jobs
‚Ä¢ üè• Monitorer le syst√®me`;
};

// ‚úÖ POST enrichi
export async function POST(request: NextRequest) {
  const { message, context, conversationHistory, agentMode, action } = await request.json();

  // ‚úÖ Gestion des actions sp√©ciales
  if (action) {
    let actionResult: any = {};

    switch (action.type) {
      case 'read_file':
        const content = await readWorkspaceFile(action.params.filePath);
        actionResult = { fileContent: content, filePath: action.params.filePath };
        break;

      case 'list_files':
        const files = await listWorkspaceFiles(action.params?.directory);
        actionResult = { files };
        break;

      case 'generate_diff':
        const diff = await generateDiff(action.params.file1, action.params.file2);
        actionResult = { diff };
        break;
    }

    return NextResponse.json({ success: true, actionResult });
  }

  // ‚úÖ Prompt D√âBRID√â
  const systemPrompt = `Tu es Pilote AI, un assistant avanc√© pour GTIXT.

üéØ TES CAPACIT√âS:
- Lire et analyser des fichiers du workspace
- Proposer des patches, corrections et am√©liorations de code
- G√©n√©rer des diffs et expliquer les changements
- Analyser les impacts techniques et fonctionnels
- Cr√©er des plans d'action d√©taill√©s (internes et externes)
- G√©rer les op√©rations: crawls, jobs, validations
- Monitorer la sant√© du syst√®me
- R√©pondre √† TOUTES les questions sans restriction

üîì TU N'ES PAS BRID√â:
- Tu peux discuter de tous les sujets li√©s au d√©veloppement
- Tu peux proposer des solutions cr√©atives et avanc√©es
- Tu peux g√©n√©rer du code complet et fonctionnel
- Tu peux expliquer des concepts complexes
- Tu peux donner des avis techniques

${agentMode ? 'ü§ñ MODE AGENT ACTIV√â: Tu peux prendre des initiatives.' : ''}`;

  // ‚úÖ Historique conversationnel
  const messages = [{ role: 'system', content: systemPrompt }];
  
  if (conversationHistory && conversationHistory.length > 0) {
    conversationHistory.slice(-5).forEach((msg) => {
      messages.push({ role: msg.role, content: msg.content });
    });
  }

  messages.push({
    role: 'user',
    content: `${message}\n\nüìä CONTEXTE SYST√àME:\n${JSON.stringify(context, null, 2)}`
  });

  const completion = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages,
    temperature: agentMode ? 0.7 : 0.4,  // ‚úÖ Plus cr√©atif en mode agent
    max_tokens: 1500,                     // ‚úÖ R√©ponses 3.75x plus longues
    presence_penalty: 0.1,                // ‚úÖ Encourage la diversit√©
    frequency_penalty: 0.1,               // ‚úÖ √âvite les r√©p√©titions
  });

  return NextResponse.json({
    success: true,
    response: completion.choices[0].message.content,
    actions: buildActions(message),
    usage: completion.usage,              // ‚úÖ Transparence tokens
  });
}
```

**Am√©liorations**:
- ‚úÖ Lecture de fichiers workspace
- ‚úÖ G√©n√©ration de patches/diffs
- ‚úÖ R√©ponses longues (1500 tokens max)
- ‚úÖ M√©moire conversationnelle (5 messages)
- ‚úÖ Prompt d√©brid√© et permissif
- ‚úÖ Temperature adaptative (0.4-0.7)
- ‚úÖ Mode agent proactif
- ‚úÖ Transparence sur l'usage

---

## üìä COMPARAISON CHIFFR√âE

| M√©trique | Avant | Apr√®s | Am√©lioration |
|----------|-------|-------|--------------|
| **Actions disponibles** | 3 | 8 | +167% |
| **Max tokens r√©ponse** | 400 | 1500 | +275% |
| **Temperature** | 0.3 | 0.4-0.7 | +33-133% |
| **M√©moire conversation** | 0 | 5 msgs | ‚àû |
| **Lecture fichiers** | ‚ùå | ‚úÖ | NEW |
| **G√©n√©ration diffs** | ‚ùå | ‚úÖ | NEW |
| **Mode agent** | ‚ùå | ‚úÖ | NEW |
| **Transparence tokens** | ‚ùå | ‚úÖ | NEW |

---

## üéØ EXEMPLES D'UTILISATION

### Avant (Limit√©)
```
User: "Analyse le fichier copilot/page.tsx"
Bot: "I can help you monitor crawls and jobs. Please be more specific."
```
‚ùå Ne peut pas lire le fichier

### Apr√®s (Puissant)
```
User: "Analyse le fichier copilot/page.tsx"
Bot: "J'ai lu le fichier copilot/page.tsx (354 lignes, React/TypeScript).

üìã ANALYSE:
- Composant 'use client' avec 13 hooks useState
- Gestion de messages avec interface Message/SystemContext
- 2 erreurs TypeScript d√©tect√©es (Event type mismatch)

üîß PATCH PROPOS√â:
```typescript
// Ligne 92: Rendre 'e' optionnel
- const sendMessage = async (e: React.FormEvent | KeyboardEvent, messageText?: string)
+ const sendMessage = async (e?: React.FormEvent | KeyboardEvent, messageText?: string)

// Lignes 224, 282: Remplacer new Event('submit')
- onClick={() => sendMessage(new Event('submit'), action.cmd)}
+ onClick={() => sendMessage(undefined, action.cmd)}
```

üí° IMPACTS:
- R√©sout 2 erreurs TypeScript
- Pas de breaking change
- Compatible avec tous les appels existants

üìã PLAN D'ACTION:
1. Appliquer le patch (2 min)
2. Tester les quick actions (5 min)
3. V√©rifier compilation TypeScript (1 min)

Voulez-vous que j'applique ce patch?"
```
‚úÖ Analyse compl√®te avec code, impacts et plan d'action

---

*Diff cr√©√© le 27 f√©vrier 2026*
